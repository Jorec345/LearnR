##data visualization
barplot(safdata)
##data visualization
bardata <- table(safdata$NewPrices)
bardata
barplot(bardata)
barplot(bardata, main = "simple bar plot", xlab = "saf prices",
ylab = "frequency")
library(robustbase)
library(dplyr)
data(hbk)
###getting just the first three column for analysis.
hbk.x <- data.matrix(hbk[,1:3])
library(MASS)
##measures of the centre or location
median(hbk.x[,1])
mean(hbk.x[,1])
##robust estimators of the centre
###trimming 20% off both tails
fit <- hm_summary(fit, robust = FALSE)
trimmedMean <- function(prices,percentBound=0.2){
n = length(prices)
sortedPrices = sort(prices)
nToBeRemoved = percentBound * n
rmfstN = sortedPrices[ -c(1:nToBeRemoved)]
rmlstN = rmfstN[1:(length(rmfstN) - nToBeRemoved)]
return(sum(rmlstN)/length(rmlstN))
}
winsoreziedMean <- function(prices,percentBound=0.2){
n = length(prices)
sortedPrices = sort(prices)
nToBeRemoved = percentBound * n
rmfstN = sortedPrices[ -c(1:nToBeRemoved)]
rmlstN = rmfstN[1:(length(rmfstN) - nToBeRemoved)]
maxVal = max(rmlstN)
minValue = min(rmlstN)
newFstSeq = rep(maxVal,nToBeRemoved)
newLStVals = rep(minValue,nToBeRemoved)
newSeq = c(newFstSeq,rmlstN)
newSeqWthTail = c(newSeq,newLStVals)
return(sum(newSeqWthTail)/length(newSeqWthTail))
}
ourMprices <- datasaf[,3]
percentremove <- 0.2
trimmedMean(ourMprices,percentremove)
winsoreziedMean(ourMprices,percentremove)
mean(ourMprices)
##consuming in the safaricom data
safaricomdata <- read.csv("safaricom prices.csv", header = TRUE)
str(safaricomdata)
##selecting data from 2019
trainData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-05")%>%
select(MarketPrice,NewDate)
##applying the robust estimators
trimmedMean(trainData$MarketPrice,percentremove)
winsoreziedMean(trainData$MarketPrice,percentremove)
mean(usedata)
###selecting data from 2020
testData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))%>%
filter(NewDate >= "2020/01/01")%>%
select(MarketPrice,NewDate)
#robust estimators
meansFunc <- function(input,percentremove = 0.2, type = 3){
if (type==1){
trimmedMean(input,percentremove)
}else if(type==2){
winsoreziedMean(input,percentremove)
} else{
mean(input)
}
}
##write a function that calculates returns
##moving avaerage
rollingmeans <- function(arr,n=15,percentremove = 0.2,type =5){
res = arr
for(i in n:length(arr)){
if (type==1){
res[i] = trimmedMean(arr[(i-n):i])
}else if(type==2){
res[i] = winsoreziedMean(arr[(i-n):i],percentremove)
} else{
res[i] = mean(arr[(i-n):i])
}
}
res
}
returnFunction <- function(inputArr){
returns = (inputArr[2:length(inputArr)]/inputArr[1:length(inputArr)-1]) - 1.0
return(c(0.0,returns))
}
returnFunction(testData$MarketPrice)
###selecting data from 2020
testData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))%>%
filter(NewDate >= "2020/01/01")%>%
select(MarketPrice,NewDate)
library(robustbase)
library(dplyr)
data(hbk)
###getting just the first three column for analysis.
hbk.x <- data.matrix(hbk[,1:3])
library(MASS)
##measures of the centre or location
median(hbk.x[,1])
mean(hbk.x[,1])
##robust estimators of the centre
###trimming 20% off both tails
fit <- hm_summary(fit, robust = FALSE)
trimmedMean <- function(prices,percentBound=0.2){
n = length(prices)
sortedPrices = sort(prices)
nToBeRemoved = percentBound * n
rmfstN = sortedPrices[ -c(1:nToBeRemoved)]
rmlstN = rmfstN[1:(length(rmfstN) - nToBeRemoved)]
return(sum(rmlstN)/length(rmlstN))
}
winsoreziedMean <- function(prices,percentBound=0.2){
n = length(prices)
sortedPrices = sort(prices)
nToBeRemoved = percentBound * n
rmfstN = sortedPrices[ -c(1:nToBeRemoved)]
rmlstN = rmfstN[1:(length(rmfstN) - nToBeRemoved)]
maxVal = max(rmlstN)
minValue = min(rmlstN)
newFstSeq = rep(maxVal,nToBeRemoved)
newLStVals = rep(minValue,nToBeRemoved)
newSeq = c(newFstSeq,rmlstN)
newSeqWthTail = c(newSeq,newLStVals)
return(sum(newSeqWthTail)/length(newSeqWthTail))
}
ourMprices <- datasaf[,3]
percentremove <- 0.2
trimmedMean(ourMprices,percentremove)
winsoreziedMean(ourMprices,percentremove)
mean(ourMprices)
##consuming in the safaricom data
safaricomdata <- read.csv("safaricom prices.csv", header = TRUE)
#Data Processing
##selecting data from 2019
trainData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-05")%>%
select(MarketPrice,NewDate)
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-05")
safaricomdata
##consuming in the safaricom data
safaricomdata <- read.csv("safaricom prices.csv", header = TRUE)
head(safaricomdata)
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d-%m-%Y"))
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))
trainData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-05")%>%
select(MarketPrice,NewDate)
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-05")
trainData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")
head(trainData)
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")%>%
select(NewDate,MarketPrice)
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")%>%
select(c(NewDate,MarketPrice))
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")%>%
select(c(NewDate,MarketPrice))
select(trainData,NewDate,MarketPrice)
? select
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")
select(trainData,MarketPrice)
dplyr::select(trainData,MarketPrice)
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")%>%
dplyr::select(NewDate,MarketPrice)
#Data Processing
##selecting data from 2019
trainData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2015-01-01",NewDate <= "2019-12-31")%>%
dplyr::select(NewDate,MarketPrice)
###selecting data from 2020
testData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%Y-%m-%d"))%>%
filter(NewDate >= "2020/01/01")%>%
select(MarketPrice,NewDate)
testData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2020-01-01")%>%
dplyr::select(MarketPrice,NewDate)
testData
###selecting data from 2020
testData <-
safaricomdata %>%
mutate(NewDate = as.Date(MarketDate,format = "%d/%m/%Y"))%>%
filter(NewDate >= "2020-01-01")%>%
dplyr::select(NewDate,MarketPrice)
trimmedMean <- function(prices,percentBound=0.2){
n = length(prices)
sortedPrices = sort(prices)
nToBeRemoved = percentBound * n
rmfstN = sortedPrices[ -c(1:nToBeRemoved)]
rmlstN = rmfstN[1:(length(rmfstN) - nToBeRemoved)]
return(sum(rmlstN)/length(rmlstN))
}
winsoreziedMean <- function(prices,percentBound=0.2){
n = length(prices)
sortedPrices = sort(prices)
nToBeRemoved = percentBound * n
rmfstN = sortedPrices[ -c(1:nToBeRemoved)]
rmlstN = rmfstN[1:(length(rmfstN) - nToBeRemoved)]
maxVal = max(rmlstN)
minValue = min(rmlstN)
newFstSeq = rep(maxVal,nToBeRemoved)
newLStVals = rep(minValue,nToBeRemoved)
newSeq = c(newFstSeq,rmlstN)
newSeqWthTail = c(newSeq,newLStVals)
return(sum(newSeqWthTail)/length(newSeqWthTail))
}
ourMprices <- safaricomdata[,3]
percentremove <- 0.2
##applying the robust estimators
trimmedMean(trainData$MarketPrice,percentremove)
winsoreziedMean(trainData$MarketPrice,percentremove)
mean(usedata)
mean(trainData$MarketPrice)
rollingmeans <- function(arr,n=15,percentremove = 0.2,type =5){
res = arr
for(i in n:length(arr)){
if (type==1){
res[i] = trimmedMean(arr[(i-n):i])
}else if(type==2){
res[i] = winsoreziedMean(arr[(i-n):i],percentremove)
} else{
res[i] = mean(arr[(i-n):i])
}
}
res
}
rollingmeans <- function(arr,n=15,percentremove = 0.2,type =5){
res = arr
for(i in n:length(arr)){
if (type==1){
res[i] = trimmedMean(arr[(i-n):i])
}else if(type==2){
res[i] = winsoreziedMean(arr[(i-n):i],percentremove)
} else{
res[i] = mean(arr[(i-n):i])
}
}
res
}
rollingmeans(trainData$MarketPrice)
returnFunction(trainDate$MarketPrice)
returnFunction(trainData$MarketPrice)
#consume in the data
safdata <- read.csv("safaricom_Prices.csv", header = TRUE)
str(safdata)
#
#create a column for returns
returns_data <-
safdata%>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (MarketPrice/NewPrices)-1)%>%
filter(nsafdate > "01/01/2019")%>%
select(returnsdata,nsafdate)
#
#create a column for returns
returns_data <-
safdata%>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (MarketPrice/NewPrices)-1)%>%
filter(nsafdate > "01/01/2019")%>%
select(returnsdata,nsafdate)
safdata%>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (MarketPrice/NewPrices)-1)
returnvec <- returnFunction(trainData$MarketPrice)
head(returnvec)
safdata%>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (NewPrices/MarketPrice)-1)
rollingmeans <- function(arr,n=15,percentremove = 0.2,type = "mean"){
res = arr
for(i in n:length(arr)){
if (type=="trimmed"){
res[i] = trimmedMean(arr[(i-n):i])
}else if(type=="winsorised"){
res[i] = winsoreziedMean(arr[(i-n):i],percentremove)
} else{
res[i] = mean(arr[(i-n):i])
}
}
return(res)
}
rollingmeans(trainData$MarketPrice,"trimmed")
rollingmeans(trainData$MarketPrice,"winsorised")
rollingmeans(trainData$MarketPrice)
rollingmeans(trainData$MarketPrice,"trimmed")
rollingmeans <- function(arr,n=15,percentremove = 0.2,type =5){
res = arr
for(i in n:length(arr)){
if (type==1){
res[i] = trimmedMean(arr[(i-n):i])
}else if(type==2){
res[i] = winsoreziedMean(arr[(i-n):i],percentremove)
} else{
res[i] = mean(arr[(i-n):i])
}
}
return(res)
}
rollingmeans(trainData$MarketPrice)
rollingmeans(trainData$MarketPrice,1)
#####Chgecking for nomrality assumption
library ggplot2
#####Chgecking for nomrality assumption
library(ggplot2)
returnDf$returns <- returnFunction(trainData$MarketPrice)
trainData$returns <- returnFunction(trainData$MarketPrice)
ggplot(trainData,aes(x = returns)) + geom_histogram()
trainData %>%
mutate(trimmedReturns = rollingmeans(returns,1),
winsorisedRetruns = rollingmeans(returns,2),
meanReturns = rollingmeans(returns,3))
meanDfs <-
trainData %>%
mutate(trimmedReturns = rollingmeans(returns,1),
winsorisedRetruns = rollingmeans(returns,2),
meanReturns = rollingmeans(returns,3))
meanDfs <-
trainData %>%
mutate(trimmedReturns = rollingmeans(returns,1),
winsorisedReturns = rollingmeans(returns,2),
meanReturns = rollingmeans(returns,3))
head(meanDfs)
ggplot(trainData,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs) + geom_histogram()
ggplot(meanDfs,aes(x = winsorisedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = meanReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = winsorisedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = meanReturns)) + geom_histogram()
rollingmeans <- function(arr,n=20,percentremove = 0.2,type =5){
res = arr
for(i in n:length(arr)){
if (type==1){
res[i] = trimmedMean(arr[(i-n):i])
}else if(type==2){
res[i] = winsoreziedMean(arr[(i-n):i],percentremove)
} else{
res[i] = mean(arr[(i-n):i])
}
}
return(res)
}
rollingmeans(trainData$MarketPrice,1)
returnFunction <- function(inputArr){
returns = (inputArr[2:length(inputArr)]/inputArr[1:length(inputArr)-1]) - 1.0
return(c(0.0,returns))
}
trainData$returns <- returnFunction(trainData$MarketPrice)
#####Chgecking for nomrality assumption
library(ggplot2)
ggplot(trainData,aes(x = returns)) + geom_histogram()
meanDfs <-
trainData %>%
mutate(trimmedReturns = rollingmeans(returns,1),
winsorisedReturns = rollingmeans(returns,2),
meanReturns = rollingmeans(returns,3))
ggplot(meanDfs,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = winsorisedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = meanReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs, aes(x=NewDate)) +
geom_line(aes(y = trimmedReturns), color = "darkred") +
geom_line(aes(y = winsorisedReturns), color = "darkblue") +
geom_line(aes(y = meanReturns), color="steelblue", linetype="twodash")
meanDfs <-
trainData %>%
mutate(trimmedReturns = rollingmeans(MarketPrice  ,1),
winsorisedReturns = rollingmeans(MarketPrice,2),
meanReturns = rollingmeans(MarketPrice,3))
ggplot(meanDfs, aes(x=NewDate)) +
geom_line(aes(y = trimmedReturns), color = "darkred") +
geom_line(aes(y = winsorisedReturns), color = "darkblue") +
geom_line(aes(y = meanReturns), color="steelblue", linetype="twodash")
ggplot(meanDfs,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = winsorisedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = meanReturns)) + geom_histogram()
meanDfs <-
trainData %>%
mutate(trimmedReturns = rollingmeans(returns,1),
winsorisedReturns = rollingmeans(returns,2),
meanReturns = rollingmeans(returns,3))
ggplot(meanDfs,aes(x = trimmedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = winsorisedReturns)) + geom_histogram()
ggplot(meanDfs,aes(x = meanReturns)) + geom_histogram()
##consuming in data
safdata <- read.csv("safaricom_Prices.csv", header = TRUE)
View(safdata)
##consuming in the data
consumedata <- read.csv("Crime_Data.csv", header = TRUE)
View(consumedata)
##consuming in data
safdata <- read.csv("safaricom_Prices.csv", header = TRUE)
returns_data <-
safdata %>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (NewPrices/MarketPrice)-1) %>%
filter(nsafdate > "2019/01/01") %>%
select(returnsdata)
str(returns_data)
##1. create a histogram
hist(returns_data$returnsdata)
##testing for normality
library(dplyr)
library("ggpubr")
##consuming in data
safdata <- read.csv("safaricom_Prices.csv", header = TRUE)
returns_data <-
safdata %>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (NewPrices/MarketPrice)-1) %>%
filter(nsafdate > "2019/01/01") %>%
select(returnsdata)
str(returns_data)
##1. create a histogram
hist(returns_data$returnsdata)
qqnorm(returns_data$returnsdata, main="QQ plot of normal data")
##1. create a histogram
hist(returns_data$returnsdata)
qqnorm(returns_data$returnsdata, main="QQ plot of normal data")
##3.Perform a Shapiro- wilk test
shapiro.test(returns_data$returnsdata)
##4. perform kolmogorov smirnov test
ks.test(returns_data$returnsdata, 'pnorm')
library("ggpubr")
library(dplyr)
library("ggpubr")
##consuming in data
safdata <- read.csv("safaricom_Prices.csv", header = TRUE)
frist20 <- safdata[1:20, "MarketPrice"]
frist20
setw(" E:/Projects/R Projects/Data Cleaning/kkk")
setwd(" E:/Projects/R Projects/Data Cleaning/kkk")
setwd(" E:/Projects/R Projects/Data Cleaning/kkk")
setwd("E:/Projects/R Projects/Data Cleaning/kkk")
getwd()
VADeaths%>%
as.numeric(VADeaths$RuralMale)
as.numeric(VADeaths$RuralMale)
##bar plots are used for ranking
#works with numeric values
library("dplyr")
library(ggplot2)
VADeaths%>%
as.numeric(VADeaths$RuralMale)
as.numeric(RuralMale, UrbanMale)
as.numeric(Rural Male, Urban Male)
as.numeric(1,3)
VADeaths%>%
as.numeric(1,3)
VADeaths
VADeaths%>%
as.numeric(colnames("RuralMale","RuralFemale","UrbanMale","UrbanFemale"))
##testing for normality
library(dplyr)
library("ggpubr")
##consuming in data
safdata <- read.csv("safaricom_Prices.csv", header = TRUE)
returns_data <-
safdata %>%
mutate(nsafdate = as.Date(MarketDate,format = "%d/%m/%Y"),
returnsdata = (NewPrices/MarketPrice)-1) %>%
filter(nsafdate > "2019/01/01") %>%
select(returnsdata)
##1. create a histogram
hist(returns_data$returnsdata)
qqnorm(returns_data$returnsdata, main="QQ plot of normal data")
##3.Perform a Shapiro- wilk test
shapiro.test(returns_data$returnsdata)
##4. perform kolmogorov smirnov test
ks.test(returns_data$returnsdata, 'pnorm')
